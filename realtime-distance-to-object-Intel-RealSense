"""
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pyrealsense2 as rs
#import keras as ks

                                     

pipe = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
# other_stream, other_format = rs.stream.infrared, rs.format.y8
other_stream, other_format = rs.stream.color, rs.format.rgb8
config.enable_stream(other_stream, 640, 480, other_format, 30)

pipe.start(config)

#skip 5 frames so exposure can auto adjust
for x in range(5):
  pipe.wait_for_frames()

frameset = pipe.wait_for_frames()
color_frame = frameset.get_color_frame()
depth_frame = frameset.get_depth_frame()

pipe.stop()
print("frames captured")

color = np.asanyarray(color_frame.get_data())
plt.rcParams["axes.grid"] = False
plt.rcParams["figure.figsize"] = [12,6]
#plt.imshow(color)

colorizer = rs.colorizer()
colorizedDepth = np.asanyarray(colorizer.colorize(depth_frame).get_data())
#plt.imshow(colorizedDepth)

align = rs.align(rs.stream.color)
frameset = align.process(frameset)

aligned_depth_frame = frameset.get_depth_frame()
 
colorized_depth = np.asanyarray(colorizer.colorize(aligned_depth_frame).get_data())

images = np.stack((color, colorized_depth))

f = plt.figure()
f.add_subplot(1,2, 1)
plt.imshow(color)
f.add_subplot(1,2, 2)
plt.imshow(colorized_depth)
plt.show(block=True)
#plt.imshow(color)
#plt.imshow(colorizedDepth)
height, width = color.shape[:2]
expected = 300
aspect = width / height
resized_image = cv2.resize(color, (round(expected * aspect), expected))
#plt.imshow(resized_image)
crop_start = round(expected * (aspect - 1) / 2)
crop_img = resized_image[0:expected, crop_start:crop_start+expected]
className = ('keshav')

xScale = 400/640
yScale = 300/480

xmin = 250/640
ymin =  80/480
xmax = 450/640
ymax = 300/480

#xmin = 250
#ymin = 80
#xmax = 400
#ymax = 300

cv2.rectangle(crop_img, (int(xmin * expected), int(ymin * expected)), 
             (int(xmax * expected), int(ymax * expected)), (255, 255, 255), 2)
cv2.putText(crop_img, className, 
            (int(xmin * expected), int(ymin * expected) - 5),
            cv2.FONT_HERSHEY_COMPLEX, 0.5, (255,255,255))

plt.imshow(crop_img)



scale = height / expected
xmin_depth = int((xmin * expected + crop_start) * scale)
ymin_depth = int((ymin * expected) * scale)
xmax_depth = int((xmax * expected + crop_start) * scale)
ymax_depth = int((ymax * expected) * scale)
xmin_depth,ymin_depth,xmax_depth,ymax_depth
cv2.rectangle(colorized_depth, (xmin_depth, ymin_depth), 
             (xmax_depth, ymax_depth), (255, 255, 255), 2)

#plt.imshow(colorized_depth)


depth = np.asanyarray(aligned_depth_frame.get_data())
print('depth0 is\n',depth)
print('depthpointzero is \n' ,depth[0,0])

xAv = round((xmin_depth+xmax_depth)/2)
yAv = round((ymin_depth+ymax_depth)/2)

print('xAv is ', xAv)
print('yAv is ', yAv)

depth = depth[xAv,yAv].astype(float)
#depth = depth[xmin_depth:xmax_depth,ymin_depth:ymax_depth].astype(float)
print('depth1 is',depth)

depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()
depth = depth * depth_scale
dist,_,_,_ = cv2.mean(depth)


print('depth2 is',depth)
print("scale is",depth_scale)
print("Detected {0} {1:.3} meters away.".format(className, dist))
